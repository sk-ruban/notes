# Lecture 3 - Bias
30 Aug 2019

## GIGO (Garbage in Garbage Out)
* ::Biased input -> Biased output::
* ::Algorithmic bias: Output of algorithm deviates from standard (Fairness)::
* Norman (MIT exp) - Psychopath AI with death as training data

### Gender 
* How does AI mistake gender? - Microsoft / Google / Megvii from African and EU parliament
* Classified by Fitzpatrick skin type and gender
* Darker skin females highest errors
* LinkedIn male name suggestions
* Google photos categorises black people as Gorillas
* Microsoft Twitter chat bot Tay

### Solutions
1. Let ::Market:: handle it: AI that detects bias
2. ::Industry self regulation::: Watchdogs to audit & certify
3. ::Legal liability:: for biased AI

## Civil Rights
*1964 Civil Rights* 
* Prohibits ::discrimination based on race / colour / religion / National Origin & ethnicity / Sex::
in org > 15 employees for hiring, pay, promotion, harassment, working conditions
* ::Cannot indicate preference on Ads::
* Bona Fide Qualifications ::(In good faith):: eg. Age: Airline Pilots

*1967 Age Discrimination (ADEA)* 
* ::Outlaws discrimination for those above 40yr in org > 20 employees::
* ::Eliminated mandatory retirement::
* ::No age preference on ads::

*1968 Fair Housing Act* 
* In buying or renting houses *unless owner occupied with <=4 units*
* ::Unlawful to print a discriminatory notice or ad with respect to sale or rental.::
* ::Unlawful to represent a dwelling isnâ€™t available when available::

*Disparate Treatment*
* ::Intentional Discrimination::

*Disparate Impact* 
* Just need to prove effect
* ::Employer uses facially neutral criterion but still discriminatory:: (eg. using postal codes)
* Power plant requiring high school diploma and aptitude test - discrimination against blacks
* Criticism:
	* ::Conservatives oppose due to forced racial quotas::
	* ::Proof is hard and hard to coordinate lawsuit::
	* ::Business necessity: Safe & efficient performance::
		* Should have used alternative practices that have less discriminatory effect
	

